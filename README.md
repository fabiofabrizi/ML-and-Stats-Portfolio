<div >
	<code><img width="50" src="https://user-images.githubusercontent.com/25181517/183914128-3fc88b4a-4ac1-40e6-9443-9a30182379b7.png" alt="Jupyter Notebook" title="Jupyter Notebook"/></code>
	<code><img width="50" src="https://user-images.githubusercontent.com/25181517/183423507-c056a6f9-1ba8-4312-a350-19bcbc5a8697.png" alt="Python" title="Python"/></code>
</div>

# ML-and-Stats-Portfolio
Work from the 'Machine Learning and Statistics' module, ATU

The *assessments* folder contains exercises that were set during the module.<br>
The *project* folder contains the Jupyter notebook for the project.


## Topic 1: Statistics

This was the first topic and covere the 'Lady tasting tea' problem by Ronald A. Fisher.
The exercise was to calculate the minimum number of cups of tea required to ensure that the probability of randomly selecting the correct cups is less than or equal to 1%.<br>
The second exercise was to take the t-test examples from the scipy documentation and explain how it works using markdown and code comments.

## Topic 2: Models

This topic dealt with models - i.e. mathematical models that can be used to represent real-world problems.
Linear regression was explored and *least-squares* fitting.<br>
The first exercise used numpy and matplotlib to plot the absolute value function, with an accompanying explanation as to why it's not typically used to fit straight lines to data.<br>
The second exercise was to explore lines of best fit and the cost function.<br>

## Topic 3: Parameters

This topic explored parameters and used second and third-order equations as examples.<br>
The exercise was to use numpy's polyfit to fit polynomials to two data sets.<br>


## Project: 

From the Keras website, recreate the time-series anomaly detection example, explaining the concepts used.<br>

The project is in the form of a Jupyter notebook and is in the *project* folder.<br>
The aim of the project is take the example from [the Keras website](https://keras.io/examples/timeseries/timeseries_anomaly_detection/) and 
expand on it to explain the concepts in more detail, so that one might know the steps to go through when designing an convolutional 
autoencoder for time series anomaly detection.
